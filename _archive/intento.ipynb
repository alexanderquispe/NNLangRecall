{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb6910c-3354-4fcc-8fff-5f3260f6d951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, namedtuple\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38894b3-3bc5-42b5-b02e-7155431e1a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import duolingo_replica as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabf353e-339f-4304-b9c7-2fe7249bbee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# min_hl  = 15 / (24 * 60)\n",
    "# max_hl  = 274\n",
    "# # ------------------------------------------------------ #\n",
    "# weights = np.random.randn( len( feature_columns ) ) * 0.01\n",
    "# fcounts = defaultdict( float )\n",
    "# lrate = .001 # learning rate\n",
    "# hlwt =.01 # alpha\n",
    "# l2wt = .1 # lambda\n",
    "# # ------------------------------------------------------ #\n",
    "# sigma = 1.\n",
    "\n",
    "# def pclip(p):\n",
    "#     # bound min/max model predictions (helps with loss optimization)\n",
    "#     return min(max(p, 0.0001), .9999)\n",
    "\n",
    "\n",
    "# def hclip(h):\n",
    "#     # bound min/max half-life\n",
    "#     return min(max(h, MIN_HALF_LIFE), MAX_HALF_LIFE)\n",
    "\n",
    "# def halflife( X, weights ):\n",
    "    \n",
    "#     try: \n",
    "        \n",
    "#         dp += X.dot( weights )\n",
    "#         return hclip( 2 ** dp )\n",
    "    \n",
    "#     except:\n",
    "        \n",
    "#         return max_hl\n",
    "    \n",
    "# def find_p( h, t ):\n",
    "    \n",
    "#     p_hat = 2 ** -Delta / h_hat\n",
    "#     p_hat = np.clip( p_hat, 0.0001, 0.9999 )\n",
    "    \n",
    "#     return p_hat\n",
    "\n",
    "# def train( dataframe_x, dataframe_y, max_iter=1000000, tolerance=1e-7, print_iter=1000 ):\n",
    "    \n",
    "#     X = dataframe_x[feature_columns].values\n",
    "#     p = dataframe_y.values.flatten()    \n",
    "#     t = dataframe_x['t'].values\n",
    "    \n",
    "#     h_hat = halflife( X, weights )\n",
    "#     p_hat = find_hat( h_hat, t )\n",
    "\n",
    "#     dlp_dw = 2. * X.T.dot( ( p_hat - p ) * np.log( 2 ) * p_hat * (  -t / h_hat  ) )\n",
    "#     dlh_dw = 2. * X.T.dot( ( h_hat - h ) *  np.log( 2 ) * h_hat )\n",
    "    \n",
    "#     for k in range( len( feature_columns ) ):\n",
    "        \n",
    "#         rate = ( 1./( 1 + p ) ) * lrate / np.sqrt(1 + self.fcounts[k])\n",
    "#         weights[ k ] -= rate * np.sum( dlp_dw * X[ : k ] )\n",
    "#         weights[ k ] -= rate * l2wt * weights[ k ] / sigma ** 2\n",
    "#         fcounts[ k ] += 1\n",
    "        \n",
    "# def losses( X, t ):\n",
    "    \n",
    "#     h_hat = halflife( X, weights )\n",
    "#     p_hat = find_p( h, t )\n",
    "#     slp   = (p - p_hat)**2\n",
    "#     slh   = (h - h_hat)**2\n",
    "    \n",
    "#     return slp, slh, p_hat, h_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53fc095c-7405-4092-a25e-f65493f451e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m max_hl  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m274\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------ #\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn( \u001b[38;5;28mlen\u001b[39m( feature_columns ) ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m      5\u001b[0m fcounts \u001b[38;5;241m=\u001b[39m defaultdict( \u001b[38;5;28mfloat\u001b[39m )\n\u001b[0;32m      6\u001b[0m lrate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.001\u001b[39m \u001b[38;5;66;03m# learning rate\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_columns' is not defined"
     ]
    }
   ],
   "source": [
    "min_hl  = 15 / (24 * 60)\n",
    "max_hl  = 274\n",
    "# ------------------------------------------------------ #\n",
    "weights = np.random.randn( len( feature_columns ) ) * 0.01\n",
    "fcounts = defaultdict( float )\n",
    "lrate = .001 # learning rate\n",
    "hlwt =.01 # alpha\n",
    "l2wt = .1 # lambda\n",
    "# ------------------------------------------------------ #\n",
    "sigma = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553cfe4-489f-499a-8b26-be9fff40ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pclip(p):\n",
    "    # bound min/max model predictions (helps with loss optimization)\n",
    "    return min(max(p, 0.0001), .9999)\n",
    "\n",
    "\n",
    "def hclip(h):\n",
    "    # bound min/max half-life\n",
    "    return min(max(h, MIN_HALF_LIFE), MAX_HALF_LIFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7345fc99-34c1-46e2-a2d9-30dfa68f5a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def halflife( X, weights ):\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        dp += X.dot( weights )\n",
    "        return hclip( 2 ** dp )\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return max_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a09205d-fe19-49f5-868c-6a65077a67ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_p( h, t ):\n",
    "    \n",
    "    p_hat = 2 ** -Delta / h_hat\n",
    "    p_hat = np.clip( p_hat, 0.0001, 0.9999 )\n",
    "    \n",
    "    return p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e69098-a300-4b42-bf66-76237352ba3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train( dataframe_x, dataframe_y, max_iter=1000000, tolerance=1e-7, print_iter=1000 ):\n",
    "    \n",
    "    X = dataframe_x[feature_columns].values\n",
    "    p = dataframe_y.values.flatten()    \n",
    "    t = dataframe_x['t'].values\n",
    "    \n",
    "    h_hat = halflife( X, weights )\n",
    "    p_hat = find_hat( h_hat, t )\n",
    "\n",
    "    dlp_dw = 2. * X.T.dot( ( p_hat - p ) * np.log( 2 ) * p_hat * (  -t / h_hat  ) )\n",
    "    dlh_dw = 2. * X.T.dot( ( h_hat - h ) *  np.log( 2 ) * h_hat )\n",
    "    \n",
    "    for k in range( len( feature_columns ) ):\n",
    "        \n",
    "        rate = ( 1./( 1 + p ) ) * lrate / np.sqrt(1 + self.fcounts[k])\n",
    "        weights[ k ] -= rate * np.sum( dlp_dw * X[ : k ] )\n",
    "        weights[ k ] -= rate * l2wt * weights[ k ] / sigma ** 2\n",
    "        fcounts[ k ] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1a889-6003-4f44-927b-e92ac09ae667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses( X, t ):\n",
    "    \n",
    "    h_hat = halflife( X, weights )\n",
    "    p_hat = find_p( h, t )\n",
    "    slp   = (p - p_hat)**2\n",
    "    slh   = (h - h_hat)**2\n",
    "    \n",
    "    return slp, slh, p_hat, h_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fcd34-4eb3-42dc-971a-2ba6e62c4199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a1957-a97c-4072-86e9-9eea41a0aef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653b28f-4129-4f6f-839e-318ddad67e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def train_update(self, inst):\n",
    "        if self.method == 'hlr':\n",
    "            base = 2.\n",
    "            p, h = self.predict(inst, base)\n",
    "            dlp_dw = 2.*(p-inst.p)*(LN2**2)*p*(inst.t/h)\n",
    "            dlh_dw = 2.*(h-inst.h)*LN2*h\n",
    "            for (k, x_k) in inst.fv:\n",
    "                rate = (1./(1+inst.p)) * self.lrate / math.sqrt(1 + self.fcounts[k])\n",
    "                # rate = self.lrate / math.sqrt(1 + self.fcounts[k])\n",
    "                # sl(p) update\n",
    "                self.weights[k] -= rate * dlp_dw * x_k\n",
    "                # sl(h) update\n",
    "                if not self.omit_h_term:\n",
    "                    self.weights[k] -= rate * self.hlwt * dlh_dw * x_k\n",
    "                # L2 regularization update\n",
    "                self.weights[k] -= rate * self.l2wt * self.weights[k] / self.sigma**2\n",
    "                # increment feature count for learning rate\n",
    "                self.fcounts[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20681e7-7b69-4f33-b222-a1185eb46f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983115d-a29b-4478-b225-ffbfeca1bfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc87360-06b1-4ccd-b17f-aad4702b8ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97709ec2-4860-476b-a05b-ed693f2b7784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b7ca4-eeee-4c56-8b96-ccad0e8a3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2. ** (-inst.t/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df56e9-2feb-4134-ac22-d576f42126a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc6170-3cc8-4dcf-8c65-7b1ea00dafd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11403e95-20d4-484e-8223-3a6d02df7470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403e601-c54f-4d52-b836-71da3377cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halflife(self, inst, base):\n",
    "    try:\n",
    "        dp = sum([self.weights[k]*x_k for (k, x_k) in inst.fv])\n",
    "        return hclip(base ** dp)\n",
    "    except:\n",
    "        return MAX_HALF_LIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef899fc-a99a-48aa-87ad-032e005b5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = 0  # Inicializamos la variable dp a 0\n",
    "\n",
    "# Iteramos sobre los elementos de inst.fv, que son pares (k, x_k)\n",
    "for (k, x_k) in inst.fv:\n",
    "    # Obtenemos el peso correspondiente de self.weights\n",
    "    peso_k = self.weights[k]\n",
    "    \n",
    "    # Calculamos el producto y lo sumamos a dp\n",
    "    dp += peso_k * x_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965eca5-5dea-48a2-97ab-ed7d3c76450a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392d8bd-fbe5-49de-8e31-fffe3953689c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b2434-5d30-4867-a589-e5a6b9f6071a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3333f-7b0d-430e-b2b0-264e56ad642b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffbf7f-c3cf-41f0-aa74-a2a59bd654f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432588e4-06e4-4694-938c-ef2b8e3738ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5439a87f-f33a-46ce-88ff-0621acaeb1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fb2b4b-efb0-4ddd-a01e-150e05af3779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data        = pd.read_csv( 'subset_1000.csv' )\n",
    "dummies     = pd.get_dummies( data[ 'lexeme' ], prefix = 'cat', dtype=float )\n",
    "dummies_col = dummies.columns.to_list()\n",
    "df          = pd.concat( [ data, dummies ], axis = 1 )\n",
    "\n",
    "pred_vars = [ 'right', 'wrong', 'bias', 't', 'h' ]\n",
    "dummies_  = dummies_col + pred_vars\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( df[ dummies_ ], \n",
    "                                                     df[ 'p' ], \n",
    "                                                     test_size    = 0.30,\n",
    "                                                     random_state = 7 )\n",
    "\n",
    "dummies_.remove('t')\n",
    "dummies_.remove('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80437b3-fd14-4b36-9322-7403d4abfd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = dr.SpacedRepetitionModelHLR(feature_columns=dummies_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5bdcb75-1790-4d11-8675-a8f2da7830c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Total Loss: 209458.93913244538\n",
      "Iteration 1000, Total Loss: 380071.3459818035\n"
     ]
    }
   ],
   "source": [
    "model.train( X_train, Y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bbe54-c29d-4dba-a1cc-00364c4ddbda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
